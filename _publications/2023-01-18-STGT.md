---
title: "Reward-Mediated, Model-Free Reinforcement-Learning Mechanisms in Pavlovian and Instrumental Tasks Are Related"
collection: publications
category: manuscripts
permalink: /publication/2023-01-18-STGT
excerpt: 'This paper relates the sign-tracking or goal-tracking tendency to relying on goal-directed or habitual learning systems.'
date: 2023-01-18
venue: 'Journal of Neuroscience'
paperurl: 'https://doi.org/10.1523/JNEUROSCI.1113-22.2022'
codeurl: 'https://github.com/frct/STGTmodel/tree/Groman-Calu-Collaboration'
citation: 'Reward-Mediated, Model-Free Reinforcement-Learning Mechanisms in Pavlovian and Instrumental Tasks Are Related
Neema Moin Afshar, Fran√ßois Cinotti, David Martin, Mehdi Khamassi, Donna J. Calu, Jane R. Taylor, Stephanie M. Groman
Journal of Neuroscience 18 January 2023, 43 (3) 458-471; DOI: 10.1523/JNEUROSCI.1113-22.2022'
---
Model-free and model-based computations are argued to distinctly update action values that guide decision-making processes. It is not known, however, if these model-free and model-based reinforcement learning mechanisms recruited in operationally based instrumental tasks parallel those engaged by pavlovian-based behavioral procedures. Recently, computational work has suggested that individual differences in the attribution of incentive salience to reward predictive cues, that is, sign- and goal-tracking behaviors, are also governed by variations in model-free and model-based value representations that guide behavior. Moreover, it is not appreciated if these systems that are characterized computationally using model-free and model-based algorithms are conserved across tasks for individual animals. In the current study, we used a within-subject design to assess sign-tracking and goal-tracking behaviors using a pavlovian conditioned approach task and then characterized behavior using an instrumental multistage decision-making (MSDM) task in male rats. We hypothesized that both pavlovian and instrumental learning processes may be driven by common reinforcement-learning mechanisms. Our data confirm that sign-tracking behavior was associated with greater reward-mediated, model-free reinforcement learning and that it was also linked to model-free reinforcement learning in the MSDM task. Computational analyses revealed that pavlovian model-free updating was correlated with model-free reinforcement learning in the MSDM task. These data provide key insights into the computational mechanisms mediating associative learning that could have important implications for normal and abnormal states.
